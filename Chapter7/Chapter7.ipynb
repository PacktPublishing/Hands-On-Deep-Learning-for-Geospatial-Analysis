{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raster Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the data, if not yet downloaded\n",
    "\n",
    "import wget\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"data.zip\"):\n",
    "    url = 'http://data.geo.admin.ch/ch.swisstopo.images-landsat25/data.zip'\n",
    "    wget.download(url,bar=None)\n",
    "else:\n",
    "    print(\"ok. data already downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the data if not yet unzipped\n",
    "\n",
    "import zipfile\n",
    "\n",
    "if not os.path.exists(\"landsat\"):\n",
    "    zip_ref = zipfile.ZipFile(\"data.zip\", 'r')\n",
    "    zip_ref.extractall(\"landsat\")\n",
    "    zip_ref.close()\n",
    "else:\n",
    "    print(\"ok. data already unzipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have the tif file \"landsat/LandsatMos25.tif\" extracted\n",
    "\n",
    "import rasterio\n",
    "\n",
    "ds = rasterio.open('landsat/LandsatMos25.tif', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.name)\n",
    "print(ds.count) # number of raster bands, in our case 3 for r,g,b\n",
    "print(ds.width, ds.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.transform)  # affine transformation pixel to crs+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.crs import CRS\n",
    "\n",
    "ds = rasterio.open('landsat/LandsatMos25.tif', 'r+')\n",
    "crs = CRS.from_epsg(21781)\n",
    "ds.crs = crs\n",
    "print(ds.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.transform * (0, 0)    # Pixel to CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "~ds.transform #Â inverse affine transformation\n",
    "~ds.transform * (0,0) # CRS to Pixel\n",
    "px, py = ~ds.transform * (612073, 267991)\n",
    "print(px,py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ds.read(1)\n",
    "g = ds.read(2)\n",
    "b = ds.read(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = np.dstack((r,g,b))  # stack r,g,b so we can display it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,9))\n",
    "ax.imshow(rgb, interpolation='bilinear')\n",
    "ax.plot(px,py, 'ro'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're downloading earthquake data from USGS:\n",
    "https://earthquake.usgs.gov/earthquakes/feed/v1.0/geojson.php\n",
    "\n",
    "This data is updated every minute\n",
    "\n",
    "* 2.5_week.geojson: All earthquakes > 2.5 from the last week\n",
    "* 2.5_month.geojson: All earthquakes with a magnitude > 2.5 from the last month\n",
    "\n",
    "We're looking at the data from last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_week.geojson\"\n",
    "#url = \"https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_month.geojson\"\n",
    "\n",
    "data = requests.get(url)\n",
    "file = open(\"earthquakes.geojson\",\"wb\")\n",
    "file.write(data.content)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "eq_gdf = gpd.read_file(\"earthquakes.geojson\")\n",
    "eq_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use GeoPandas to load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simplify the output and only take most important rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = eq_gdf[[\"time\",\"mag\", \"place\",\"geometry\"]].copy()\n",
    "eq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the histogramm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "eq.mag.hist(bins=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamps in UTC are not really human readable...\n",
    "Let's convert them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "data = []\n",
    "for row in range(0,len(eq)):\n",
    "    time = eq.iloc[row].time\n",
    "    t = str(datetime.fromtimestamp(time/1000.0, timezone.utc))\n",
    "    data.append(t)\n",
    "    \n",
    "eq[\"time_utc\"] = data\n",
    "eq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = eq.drop(['time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Natural Earth Dataset with all Polygons of all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfAdmin0 = gpd.read_file(\"data/ne_10m_admin_0_countries/ne_10m_admin_0_countries.shp\", encoding=\"utf-8\")\n",
    "gdfAdmin0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = gdfAdmin0.plot(figsize=(15,9), color=\"black\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq.sort_values([\"mag\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point Clouds\n",
    "\n",
    "\n",
    "first we unzip the folder to get the .las file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "if not os.path.exists(\"../data/points/26825_12475.las\"):\n",
    "    zip_ref = zipfile.ZipFile(\"../data/points/26825_12475.zip\", 'r')\n",
    "    zip_ref.extractall(\"../data/points/\")\n",
    "    zip_ref.close()\n",
    "else:\n",
    "    print(\"ok. data already unzipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laspy.file import File\n",
    "import numpy as np\n",
    "\n",
    "file = File('../data/points/26825_12475.las', mode='r')\n",
    "coords = np.dstack((file.x, file.y, file.z))\n",
    "file.close()\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyConLt",
   "language": "python",
   "name": "pyconlt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
